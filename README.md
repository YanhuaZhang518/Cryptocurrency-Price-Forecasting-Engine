# ğŸª™ Cryptocurrency Price Forecasting Engine  
**Predicting Ethereum (ETH) prices using LSTM neural networks and on-chain Uniswap v3 data**

![Python](https://img.shields.io/badge/Python-3.10%2B-blue.svg)
![TensorFlow](https://img.shields.io/badge/TensorFlow-2.x-orange.svg)
![License](https://img.shields.io/badge/License-MIT-green.svg)
![Status](https://img.shields.io/badge/Status-Completed-brightgreen.svg)

---

## ğŸ“˜ Overview
This project presents a **deep learningâ€“based approach** for forecasting **Ethereum (ETH)** prices using **Long Short-Term Memory (LSTM)** networks.  
Unlike traditional models that focus on a single cryptocurrency, this model integrates **multi-token on-chain data** (price and liquidity) retrieved from **Uniswap v3** via **The Graph API**, offering a comprehensive view of the decentralized market.

The system demonstrates how on-chain market data and advanced time-series models can be combined for **robust and interpretable price prediction**.

---

## ğŸš€ Key Features
- ğŸ”— **On-chain data integration:** fetches Uniswap v3 token data (price, liquidity, volume) using GraphQL via The Graph.  
- âš™ï¸ **Automated preprocessing:** handles missing data, interpolates values, and normalizes features.  
- ğŸ§  **Model comparison:** evaluates **LSTM**, **GRU**, and **Transformer** architectures.  
- ğŸ“Š **Performance metrics:** assesses results using RMSE, MSE, MAE, and RÂ².  
- ğŸ§¾ **Experimental findings:** compares ETH-only vs multi-token datasets to evaluate the impact on accuracy.  

---

## ğŸ§  Methodology

### 1ï¸âƒ£ Data Extraction
Data is collected automatically from **Uniswap v3â€™s subgraph** using **GraphQL** queries.  
The pipeline retrieves:
- Token prices  
- Liquidity and volume  
- Time-based pool data  

The results are cleaned, interpolated, and saved as structured **JSON files** for model training.

### 2ï¸âƒ£ Feature Engineering
- Retains **High**, **Low**, and **Close** price features.  
- Removes irrelevant data such as raw transaction volume.  
- Standardizes prices for model input.  

### 3ï¸âƒ£ Model Architectures
Three deep learning models were implemented:

| Model | Highlights |
|--------|-------------|
| **LSTM** | Best performance in learning temporal dependencies |
| **GRU** | Lightweight and efficient recurrent architecture |
| **Transformer (Encoder-only)** | Uses attention for contextual time-series representation |

### 4ï¸âƒ£ Evaluation Metrics
| Metric | Description |
|---------|-------------|
| **MSE** | Mean Squared Error â€“ measures average squared deviation |
| **RMSE** | Root Mean Squared Error â€“ penalizes large prediction errors |
| **MAE** | Mean Absolute Error â€“ robust to outliers |
| **RÂ²** | Coefficient of Determination â€“ how well predictions explain variance |

---

## ğŸ“Š Results Summary

| Model | Sequence Length | RMSE | MSE | MAE | RÂ² |
|--------|----------------|------|------|------|----|
| **LSTM** | 5 | ğŸŸ¢ **0.03907** | **0.00153** | **0.03360** | **0.89620** |
| GRU | 4 | 0.03848 | 0.00551 | 0.03321 | 0.89983 |
| Transformer | 5 | 0.04962 | 0.00246 | 0.03939 | 0.83260 |

> âœ… **Best Model:** LSTM with sequence length 5  
> Stable training, lowest error, and no overfitting observed.

---

## ğŸ§© Key Findings
- **ETH-only training** yields higher accuracy than multi-crypto datasets (ETH, BTC, LINK).  
- **LSTM** demonstrates superior performance in stability and interpretability.  
- **Transformer** models require larger batch sizes (â‰¥8) to stabilize learning.  
- Using multiple token datasets **increases computation time** without improving results.

---

## ğŸ”® Future Improvements
- Incorporate **external features** such as macroeconomic indicators or social sentiment.  
- Explore **hybrid Transformerâ€“LSTM** architectures for time-series forecasting.  
- Add **decoder layers** to Transformer models for full-sequence prediction.  
- Extend evaluation to **multi-asset prediction** in DeFi markets.

---

## ğŸ› ï¸ Tech Stack

| Category | Technologies |
|-----------|---------------|
| **Language** | Python 3.x |
| **Libraries** | TensorFlow, Keras, NumPy, Pandas, Matplotlib |
| **APIs** | GraphQL via The Graph |
| **Data Source** | Uniswap v3 Subgraph |
| **Modeling** | LSTM, GRU, Transformer |
| **Visualization** | Matplotlib, Seaborn |

---

## ğŸ“‚ Project Structure
Cryptocurrency-Price-Forecasting-Engine/
â”‚
â”œâ”€â”€ data/ # On-chain data from Uniswap v3 (JSON/CSV)
â”œâ”€â”€ models/ # Saved model weights and architectures
â”œâ”€â”€ notebooks/ # Jupyter notebooks for experiments
â”œâ”€â”€ src/
â”‚ â”œâ”€â”€ data_fetch.py # GraphQL data extraction from The Graph
â”‚ â”œâ”€â”€ preprocess.py # Data cleaning and feature engineering
â”‚ â”œâ”€â”€ train_lstm.py # LSTM model training
â”‚ â”œâ”€â”€ train_gru.py # GRU model training
â”‚ â”œâ”€â”€ train_transformer.py # Transformer training
â”‚ â””â”€â”€ evaluate.py # Model evaluation and metrics
â””â”€â”€ README.md

---

## âš™ï¸ Installation & Usage

### ğŸ§© Requirements
Ensure you have the following installed:
- Python 3.8+
- pip

Then install dependencies:
```bash
pip install -r requirements.txt


â–¶ï¸ Running the Model
To fetch and preprocess data:

python src/data_fetch.py
python src/preprocess.py

To train the LSTM model:
python src/train_lstm.py


To evaluate the trained model:
python src/evaluate.py

ğŸ‘¥ Authors
Western University â€” Department of Electrical and Computer Engineering
Name	Email
James Zhong	pzhong22@uwo.ca
Xi Feng	xfeng269@uwo.ca
Wenyi Yao	wyao45@uwo.ca
Yanhua Zhang	yzha5778@uwo.ca
Zelin Zhang	zzha973@uwo.ca

ğŸ“š Citation
If you use this work in your research, please cite:
Zhang, Y., Zhong, J., Feng, X., Yao, W., & Zhang, Z. (2025).
Cryptocurrency Price Forecasting Engine Using LSTM with On-Chain Uniswap Data.
Western University, London, Canada.
